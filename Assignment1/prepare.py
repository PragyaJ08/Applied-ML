# -*- coding: utf-8 -*-
"""prepare.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DOjmqHIL6W51LgLS5IUL9todtw48oil0
"""

#imports and downloads

import pandas as pd
import numpy as np
import regex as re
import nltk
from nltk.stem import WordNetLemmatizer
from nltk.corpus import wordnet 
import string
from sklearn.model_selection import train_test_split
nltk.download('stopwords')
nltk.download('punkt')
from nltk.corpus import stopwords
stop_words=set(stopwords.words('english'))

#nltk.download('all')

#uploading the data

file = "/content/drive/MyDrive/smsspamcollection/SMSSpamCollection"

data=pd.read_csv(file, sep='\t', header=None, names=['spam', 'mssg'])

print(data)

# from google.colab import drive
# drive.mount('/content/drive')

print(data.info())

#tokenizing the words

word_tokens = []
regex=r"\w+"
for i in range(len(data.mssg)):
    word_tokens.append(re.findall(regex,data.mssg[i]))

print(word_tokens)

#lemmatization

lemmatizer = WordNetLemmatizer()

filtered_word_tokens=[]
for i in range(len(word_tokens)):

    temp=[]

    for j in range(len(word_tokens[i])):
        
        if word_tokens[i][j].lower() in stop_words:
            continue
            
        elif word_tokens[i][j] in string.punctuation:
            continue
            
        else:
            temp.append(lemmatizer.lemmatize(word_tokens[i][j]).lower())   

    filtered_word_tokens.append(temp)      

#printing the filtered word tokens after lemmatization
print(filtered_word_tokens)

data['mssg_tokenize'] = filtered_word_tokens
data

#train test split
train_mssg, test_mssg, train_spam, test_spam = train_test_split(data.mssg_tokenize, data.spam, test_size = 0.1, random_state = 42)

#train val split
train_mssg, val_mssg, train_spam, val_spam = train_test_split(train_mssg, train_spam, test_size = 0.1, random_state = 42)

print(val_mssg)

df_train=pd.DataFrame({'train_mssg': train_mssg,'train_spam': train_spam})
df_val=pd.DataFrame({'val_mssg': val_mssg,'val_spam': val_spam})
df_test=pd.DataFrame({'test_mssg': test_mssg,'test_spam': test_spam})

df_train.to_csv('/content/drive/MyDrive/Spam_folder/train.csv',index=False)
df_val.to_csv('/content/drive/MyDrive/Spam_folder/validation.csv',index=False)
df_test.to_csv('/content/drive/MyDrive/Spam_folder/test.csv',index=False)



